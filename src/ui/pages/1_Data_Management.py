"""
Gesti√≥n de Datos - M√≥dulo de Administraci√≥n de √çndices BOE
============================================================

Este m√≥dulo permite la gesti√≥n completa de los √≠ndices vectoriales del BOE,
incluyendo construcci√≥n desde cero, actualizaci√≥n incremental y procesamiento ETL.

Autor: jbarrero
Fecha: Septiembre 2025
"""

import streamlit as st
import os
import sys
import datetime
from datetime import timedelta
from pathlib import Path

# Obtener directorio ra√≠z del proyecto (subir desde src/ui/pages/)
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent

# Agregar src al path para imports absolutos
sys.path.insert(0, str(PROJECT_ROOT / "src"))

# Importar m√≥dulos con manejo de errores
try:
    from lib.index_builder import build_index_from_parquets, get_parquet_files_from_directory
    from pipeline_completo import PipelineBOE
    imports_ok = True
except ImportError as e:
    st.error(f"Error al importar m√≥dulos: {e}")
    build_index_from_parquets = None
    get_parquet_files_from_directory = None
    PipelineBOE = None
    imports_ok = False

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Gesti√≥n de Datos - BoeFacil",
    page_icon="üîß",
    layout="wide",
    initial_sidebar_state="expanded"
)

def main():
    """Funci√≥n principal de la p√°gina de gesti√≥n de datos"""
    
    # T√≠tulo principal con estilo
    st.markdown("""
    <div style="padding: 1rem 0; border-bottom: 2px solid #ff6b35;">
        <h1 style="color: #2c3e50; margin: 0;">üîß Gesti√≥n de Datos</h1>
        <p style="color: #7f8c8d; margin: 0.5rem 0 0 0;">
            Administraci√≥n completa de √≠ndices vectoriales BOE
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Espacio
    st.markdown("<br>", unsafe_allow_html=True)
    
    # Sidebar para navegaci√≥n
    with st.sidebar:
        st.markdown("### üè† Navegaci√≥n")
        
        # Bot√≥n de regreso
        if st.button("üè† P√°gina Principal", use_container_width=True, type="secondary"):
            st.switch_page("streamlit_app.py")
        
        st.markdown("---")
        
        st.markdown("### üìã Procesos disponibles")
        
        # Selector de proceso
        proceso_seleccionado = st.selectbox(
            "Selecciona el proceso:",
            [
                "Construcci√≥n de √çndice",
                "Actualizaci√≥n Incremental por d√≠a",
            ],
            index=0
        )
        
        st.markdown("---")
        
        # Informaci√≥n de estado del sistema
        st.markdown("### ‚ÑπÔ∏è Estado del Sistema")
        
        # Verificar estado del √≠ndice actual
        indices_dir = PROJECT_ROOT / "indices"
        if indices_dir.exists() and (indices_dir / "boe_index.faiss").exists():
            st.success("‚úÖ √çndice existente detectado")
            metadata_file = indices_dir / "metadata.json"
            if metadata_file.exists():
                try:
                    import json
                    with open(metadata_file, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                    
                    total_chunks = len(metadata) if isinstance(metadata, list) else metadata.get('total_vectors', 0)
                    st.info(f"üìä Chunks actuales: {total_chunks:,}")
                    
                    # Informaci√≥n adicional si existe
                    report_file = indices_dir / "construction_report.json"
                    if report_file.exists():
                        with open(report_file, 'r', encoding='utf-8') as f:
                            report = json.load(f)
                        if 'construction_date' in report:
                            st.info(f"üìÖ √öltima construcci√≥n: {report['construction_date']}")
                
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Error leyendo metadata: {str(e)}")
        else:
            st.warning("‚ö†Ô∏è No se encontr√≥ √≠ndice existente")
        
        # Directorio de datos
        samples_dir = PROJECT_ROOT / "samples"
        if samples_dir.exists():
            parquet_files = list(samples_dir.rglob("*.parquet"))  # B√∫squeda recursiva
            st.info(f"üìÅ Archivos parquet: {len(parquet_files)} (total)")
        else:
            st.error("‚ùå Directorio de origen de datos no encontrado")

    # Contenido principal basado en el proceso seleccionado
    if "Construcci√≥n de √çndice" in proceso_seleccionado:
        nueva_construccion()
    elif "Actualizaci√≥n Incremental por d√≠a" in proceso_seleccionado:
        actualizacion_dia()

def nueva_construccion():
    """Interfaz para la Construcci√≥n de √çndice desde cero"""

    st.markdown("## üèóÔ∏è Construcci√≥n de √çndice desde Cero")

    st.markdown("""
    <div style="background-color: #e8f4f8; padding: 1rem; border-radius: 0.5rem; margin: 1rem 0;">
        <h4 style="color: #2c3e50; margin-top: 0;">üìã Descripci√≥n del Proceso</h4>
        <p style="margin-bottom: 0;">
            Este proceso construye un √≠ndice vectorial completamente nuevo desde los archivos parquet disponibles
            en la carpeta especificada. Se eliminar√° cualquier √≠ndice existente y se crear√° uno nuevo.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Secci√≥n de configuraci√≥n
    st.markdown("### ‚öôÔ∏è Configuraci√≥n de Construcci√≥n")
    
    # Selector de carpeta origen
    st.markdown("#### üìÅ Carpeta de Datos Origen")
    
    # Carpeta por defecto
    carpeta_por_defecto = str(PROJECT_ROOT / "samples")
    
    carpeta_origen = st.text_input(
        "Ruta de la carpeta con archivos parquet:",
        value=carpeta_por_defecto,
        help="Especifica la ruta completa de la carpeta que contiene los archivos parquet a procesar"
    )
    
    # Verificar carpeta y mostrar archivos disponibles
    carpeta_path = Path(carpeta_origen)
    
    if carpeta_path.exists() and carpeta_path.is_dir():
        parquet_files = list(carpeta_path.rglob("*.parquet"))  # B√∫squeda recursiva
        parquet_files.sort()
        
        if parquet_files:
            st.success(f"‚úÖ Carpeta v√°lida encontrada: `{carpeta_origen}`")
            st.info(f"üìä **Archivos parquet detectados:** {len(parquet_files)} (incluyendo subcarpetas)")
            
            # Mostrar lista de archivos en un expander
            with st.expander(f"üìÑ Ver archivos ({len(parquet_files)} archivos)", expanded=False):
                for i, archivo in enumerate(parquet_files, 1):
                    file_size = archivo.stat().st_size / (1024 * 1024)  # MB
                    # Mostrar ruta relativa desde la carpeta origen
                    ruta_relativa = archivo.relative_to(carpeta_path)
                    st.write(f"{i}. `{ruta_relativa}` ({file_size:.1f} MB)")
            
            archivos_validos = True
            
        else:
            st.warning(f"‚ö†Ô∏è No se encontraron archivos parquet en: `{carpeta_origen}`")
            archivos_validos = False
    else:
        st.error(f"‚ùå La carpeta no existe o no es v√°lida: `{carpeta_origen}`")
        archivos_validos = False
    
    # Secci√≥n de advertencias y confirmaciones
    st.markdown("### ‚ö†Ô∏è Advertencias Importantes")
    
    st.warning("""
    **ATENCI√ìN:** Esta operaci√≥n:
    - Eliminar√° el √≠ndice vectorial existente si existe
    - Procesar√° todos los archivos parquet de la carpeta especificada
    - Puede tardar varios minutos dependiendo del volumen de datos
    - Requiere espacio en disco suficiente para el nuevo √≠ndice
    """)
    
    # Confirmaci√≥n del usuario
    confirmacion = st.checkbox(
        "He le√≠do las advertencias y confirmo que deseo proceder con la construcci√≥n del √≠ndice",
        value=False
    )
    
    # Bot√≥n de construcci√≥n
    st.markdown("### üöÄ Iniciar Construcci√≥n")
    
    col_btn1, col_btn2, col_btn3 = st.columns([1, 2, 1])
    
    with col_btn2:
        if st.button(
            "üèóÔ∏è Construir √çndice",
            disabled=not confirmacion or not archivos_validos,
            use_container_width=True,
            type="primary"
        ):
            ejecutar_construccion_indice(carpeta_origen)

def actualizacion_dia():
    """Interfaz para el procesamiento ETL Completo de un d√≠a espec√≠fico del BOE"""

    st.markdown("## üîÑ Procesamiento ETL Completo de un d√≠a espec√≠fico del BOE")

    st.markdown("""
    <div style="background-color: #e8f4f8; padding: 1rem; border-radius: 0.5rem; margin: 1rem 0;">
        <h4 style="color: #2c3e50; margin-top: 0;">üìã Descripci√≥n del Proceso</h4>
        <p style="margin-bottom: 0;">
            Este proceso ejecuta el pipeline completo para un d√≠a espec√≠fico del BOE desde la descarga
            hasta la generaci√≥n de embeddings e indexaci√≥n FAISS. Los datos se organizan por fecha 
            en subdirectorios (YYYYMMDD).
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Pipeline de pasos
    st.markdown("### üîÑ Pipeline de Procesamiento")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **Pasos del Pipeline:**
        1. üì• Descarga sumario BOE (JSON)
        2. üîÑ Aplanado y descarga de cuerpos
        3. üìù Conversi√≥n HTML ‚Üí Markdown
        4. ‚úÇÔ∏è Generaci√≥n de chunks
        5. üß† Generaci√≥n de embeddings
        6. üìä Actualizaci√≥n √≠ndice FAISS
        """)
    
    with col2:
        st.markdown("""
        **Estructura por fecha:**
        - `samples/YYYYMMDD/json/` ‚Üí Sumarios BOE
        - `samples/YYYYMMDD/parquet/` ‚Üí Datos aplanados
        - `samples/YYYYMMDD/chunks/` ‚Üí Chunks de texto
        - `samples/YYYYMMDD/embeddings/` ‚Üí Embeddings
        - `indices/` ‚Üí √çndice FAISS compartido
        """)
    
    # Configuraci√≥n de fecha (un solo d√≠a)
    st.markdown("### üìÖ Selecci√≥n de Fecha")
    
    fecha_boe = st.date_input(
        "Fecha del BOE a procesar:",
        value=datetime.date.today() - timedelta(days=1),  # Ayer por defecto
        help="Selecciona un d√≠a espec√≠fico para procesar. Los datos se guardar√°n en samples/YYYYMMDD/"
    )
    
    # Informaci√≥n de la fecha seleccionada
    fecha_str = fecha_boe.strftime('%Y-%m-%d')
    fecha_dir = fecha_boe.strftime('%Y%m%d')
    
    st.info(f"""
    **üìä Fecha seleccionada:** {fecha_str}
    
    **üìÅ Directorio de destino:** `samples/{fecha_dir}/`
    
    **üìÖ D√≠a de la semana:** {fecha_boe.strftime('%A')} ({fecha_boe.strftime('%d de %B de %Y')})
    """)
    
    # Configuraci√≥n avanzada
    with st.expander("‚öôÔ∏è Configuraci√≥n Avanzada", expanded=False):
        
        col_config1, col_config2 = st.columns(2)
        
        with col_config1:
            directorio_base = st.text_input(
                "Directorio base:",
                value="samples",
                help="Directorio donde se guardar√°n todos los datos procesados (se crear√° subdirectorio por fecha)"
            )
            
            modelo_embeddings = st.selectbox(
                "Modelo de embeddings:",
                ["pablosi/bge-m3-trained-2", "BAAI/bge-m3"],
                index=0,
                help="Modelo para generar embeddings de texto"
            )
        
        with col_config2:
            max_tokens_chunk = st.number_input(
                "M√°ximo tokens por chunk:",
                min_value=100,
                max_value=2000,
                value=1000,
                help="N√∫mero m√°ximo de tokens por chunk de texto"
            )
            
            batch_size = st.number_input(
                "Batch size embeddings:",
                min_value=1,
                max_value=128,
                value=32,
                help="Tama√±o del lote para generar embeddings (auto-detectado si se deja por defecto)"
            )
    
    # Advertencias
    st.markdown("### ‚ö†Ô∏è Advertencias Importantes")
    
    st.warning(f"""
    **ATENCI√ìN:** Este proceso:
    - Descargar√° datos del BOE para la fecha {fecha_str} (requiere conexi√≥n a internet)
    - Puede tardar entre 15-30 minutos para un d√≠a promedio
    - Crear√° el directorio `samples/{fecha_dir}/` con toda la estructura de datos
    - Utilizar√° GPU si est√° disponible para generar embeddings
    - Actualizar√° el √≠ndice vectorial existente (debe existir un √≠ndice base)
    - Los archivos de un d√≠a pueden ocupar entre 50-200 MB dependiendo del contenido
    """)
    
    # Confirmaci√≥n
    confirmacion_pipeline = st.checkbox(
        f"He le√≠do las advertencias y confirmo que deseo procesar el BOE del {fecha_str}",
        value=False,
        help="Confirma que entiendes el proceso y que se crear√° la estructura de datos por fecha"
    )
    
    # Bot√≥n de ejecuci√≥n
    st.markdown("### üöÄ Ejecutar Pipeline")
    
    col_btn1, col_btn2, col_btn3 = st.columns([1, 2, 1])
    
    with col_btn2:
        if st.button(
            f"üîÑ Procesar BOE del {fecha_str}",
            disabled=not confirmacion_pipeline,
            use_container_width=True,
            type="primary"
        ):
            ejecutar_pipeline_etl_completo(
                fecha=fecha_str,
                directorio_base=directorio_base,
                modelo_embeddings=modelo_embeddings,
                max_tokens_chunk=max_tokens_chunk,
                batch_size=batch_size
            )

def ejecutar_construccion_indice(carpeta_origen):
    """Ejecuta la construcci√≥n del √≠ndice vectorial"""
    
    try:
        # Crear contenedor de progreso
        progress_container = st.empty()
        
        with progress_container.container():
            st.markdown("### üîÑ Construcci√≥n en Progreso...")
            
            # Barra de progreso principal
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # √Årea de logs detallados
            with st.expander("üìã Logs Detallados", expanded=False):
                log_area = st.empty()
            
            # Obtener lista de archivos parquet (b√∫squeda recursiva)
            carpeta_path = Path(carpeta_origen)
            parquet_files = list(carpeta_path.rglob("*.parquet"))
            
            if not parquet_files:
                st.error("‚ùå No se encontraron archivos parquet en la carpeta especificada")
                return
            
            # Configurar rutas de salida
            output_dir = PROJECT_ROOT / "indices"
            index_path = output_dir / "boe_index.faiss"
            metadata_path = output_dir / "metadata.json"
            report_path = output_dir / "construction_report.json"
            
            # Crear directorio de salida si no existe
            output_dir.mkdir(exist_ok=True)
            
            # Actualizar progreso y estado
            status_text.text("Inicializando construcci√≥n del √≠ndice...")
            progress_bar.progress(10)
            log_area.text("üìÇ Archivos encontrados: " + ", ".join([f.name for f in parquet_files[:5]]) + 
                         (f" ... y {len(parquet_files)-5} m√°s" if len(parquet_files) > 5 else ""))
            
            status_text.text(f"Procesando {len(parquet_files)} archivos parquet...")
            progress_bar.progress(25)
            log_area.text(f"üìä Iniciando construcci√≥n con {len(parquet_files)} archivos\nüóÇÔ∏è Destino: {index_path}")
            
            # Construir √≠ndice usando la funci√≥n importada
            if build_index_from_parquets and imports_ok:
                try:
                    status_text.text("Construyendo √≠ndice FAISS...")
                    progress_bar.progress(50)
                    
                    # Convertir paths a strings para la funci√≥n
                    parquet_file_paths = [str(f) for f in parquet_files]
                    
                    log_area.text(f"üìä Llamando a build_index_from_parquets...\nüìÅ Archivos: {len(parquet_file_paths)}\nüìù Destino √≠ndice: {index_path}\nüìÑ Destino metadata: {metadata_path}")
                    
                    # Llamar a la funci√≥n real de construcci√≥n
                    result = build_index_from_parquets(
                        parquet_files=parquet_file_paths,
                        output_index_path=str(index_path),
                        output_metadata_path=str(metadata_path),
                        index_type="IVF",
                        dimension=1024
                    )
                    
                    progress_bar.progress(75)
                    status_text.text("Optimizando y guardando √≠ndice...")
                    
                    # Crear reporte de construcci√≥n
                    import datetime
                    
                    # Manejar el resultado que puede ser un objeto VectorDatabase
                    result_info = "Construcci√≥n completada"
                    if result:
                        if hasattr(result, 'index') and hasattr(result, 'metadata'):
                            # Es un objeto VectorDatabase, extraer informaci√≥n relevante
                            try:
                                total_vectors = result.index.ntotal if hasattr(result.index, 'ntotal') else 'Desconocido'
                                result_info = f"√çndice FAISS creado con {total_vectors} vectores"
                            except:
                                result_info = "Objeto VectorDatabase creado exitosamente"
                        else:
                            # Convertir a string si es serializable
                            try:
                                result_info = str(result)
                            except:
                                result_info = "Construcci√≥n completada"
                    
                    report_data = {
                        "construction_date": datetime.datetime.now().isoformat(),
                        "source_directory": str(carpeta_path),
                        "files_processed": len(parquet_file_paths),
                        "index_path": str(index_path),
                        "metadata_path": str(metadata_path),
                        "result": result_info
                    }
                    
                    with open(report_path, 'w', encoding='utf-8') as f:
                        import json
                        json.dump(report_data, f, indent=2, ensure_ascii=False)
                    
                    progress_bar.progress(90)
                    log_area.text(f"‚úÖ √çndice construido exitosamente\nüìä Resultado: {result_info}\nüìÑ Reporte guardado en: {report_path}")
                    
                except Exception as construction_error:
                    st.error(f"‚ùå Error durante la construcci√≥n del √≠ndice: {str(construction_error)}")
                    log_area.text(f"‚ùå Error detallado: {str(construction_error)}\n‚ùå Tipo de error: {type(construction_error).__name__}")
                    
                    # Mostrar informaci√≥n adicional del error en el debug
                    import traceback
                    error_traceback = traceback.format_exc()
                    
                    with st.expander("üîç Stack Trace Completo", expanded=False):
                        st.code(error_traceback)
                    
                    return
            else:
                st.error("‚ùå No se pudieron importar las funciones de construcci√≥n de √≠ndice")
                return
            
            status_text.text("¬°Construcci√≥n completada!")
            progress_bar.progress(100)
            
            # Mensaje de √©xito
            st.success(f"""
            ‚úÖ **√çndice construido exitosamente**
            
            - Carpeta origen: `{carpeta_origen}`
            - Archivos procesados: {len(parquet_files)}
            - √çndice guardado en: `indices/`
            """)
            
            # Aviso de recarga autom√°tica
            st.info("""
            üîÑ **Reinicia la aplicaci√≥n para usar el nuevo √≠ndice...**

            La aplicaci√≥n necesita reiniciarse para cargar el nuevo √≠ndice vectorial.
            """)
            
            # Esperar un momento para que el usuario lea el mensaje
            import time
            time.sleep(3)
            
            # Limpiar cache y recargar aplicaci√≥n
            st.cache_resource.clear()
            st.rerun()
    
    except Exception as e:
        st.error(f"‚ùå Error durante la construcci√≥n: {str(e)}")
        
        # √Årea de debugging
        with st.expander("üîç Informaci√≥n de Debug", expanded=False):
            st.code(str(e))

def ejecutar_pipeline_etl_completo(
    fecha: str,
    directorio_base: str,
    modelo_embeddings: str,
    max_tokens_chunk: int,
    batch_size: int
):
    """Ejecuta el pipeline ETL completo de procesamiento BOE para una fecha espec√≠fica"""
    
    try:
        # Verificar que el pipeline est√© disponible
        if not PipelineBOE or not imports_ok:
            st.error("‚ùå No se pudo importar el m√≥dulo del pipeline completo")
            return
        
        # Convertir fecha a formato YYYYMMDD para directorio
        fecha_dt = datetime.datetime.strptime(fecha, '%Y-%m-%d')
        fecha_dir = fecha_dt.strftime('%Y%m%d')
        
        # Crear contenedor de progreso
        progress_container = st.empty()
        
        with progress_container.container():
            st.markdown("### üîÑ Pipeline ETL en Progreso...")
            
            # Informaci√≥n del proceso
            st.info(f"""
            **Configuraci√≥n del pipeline:**
            - üìÖ Fecha: {fecha}
            - üìÅ Directorio base: `{directorio_base}`
            - ÔøΩ Directorio espec√≠fico: `{directorio_base}/{fecha_dir}/`
            - üß† Modelo embeddings: `{modelo_embeddings}`
            - ‚úÇÔ∏è Tokens por chunk: {max_tokens_chunk}
            - üîÑ Batch size: {batch_size}
            - üìä Modo: Actualizar √≠ndice existente
            """)
            
            # Barra de progreso principal (6 pasos)
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # √Årea de logs en tiempo real
            log_container = st.container()
            with log_container:
                st.markdown("#### üìã Logs del Pipeline")
                log_area = st.empty()
            
            # Inicializar pipeline
            status_text.text("Inicializando pipeline...")
            progress_bar.progress(0)
            
            try:
                # Crear instancia del pipeline con configuraci√≥n personalizada
                pipeline = PipelineBOE(
                    base_dir=directorio_base,
                    fecha_procesamiento=fecha_dir
                )
                
                # Aplicar configuraciones personalizadas
                pipeline.embedding_model_name = modelo_embeddings
                pipeline.max_tokens_per_chunk = max_tokens_chunk
                if batch_size > 0:
                    pipeline.batch_size = batch_size
                
                log_area.text(f"‚úÖ Pipeline inicializado\nüìÅ Directorio base: {directorio_base}\nüìÇ Directorio fecha: {fecha_dir}\nüß† Modelo: {modelo_embeddings}")
                
                # Paso 1: Descarga BOE
                status_text.text("Paso 1/6: Descargando sumario BOE...")
                progress_bar.progress(1/6)
                
                resultado_paso1 = pipeline.paso_1_descargar_boe(fecha)
                if not resultado_paso1:
                    raise Exception("Error en la descarga de sumario BOE")
                
                log_area.text(f"‚úÖ Paso 1 completado: Sumario BOE descargado para {fecha}")
                
                # Paso 2: Aplanado de datos
                status_text.text("Paso 2/6: Aplanando datos y descargando cuerpos...")
                progress_bar.progress(2/6)
                
                resultado_paso2 = pipeline.paso_2_aplanar_y_descargar_cuerpos()
                if not resultado_paso2:
                    raise Exception("Error en el aplanado de datos")
                
                log_area.text(f"‚úÖ Paso 2 completado: Datos aplanados y cuerpos descargados")
                
                # Paso 3: Conversi√≥n HTML ‚Üí Markdown
                status_text.text("Paso 3/6: Convirtiendo HTML a Markdown...")
                progress_bar.progress(3/6)
                
                resultado_paso3 = pipeline.paso_3_convertir_html_markdown()
                if not resultado_paso3:
                    raise Exception("Error en la conversi√≥n HTML ‚Üí Markdown")
                
                log_area.text(f"‚úÖ Paso 3 completado: HTML convertido a Markdown")
                
                # Paso 4: Generaci√≥n de chunks
                status_text.text("Paso 4/6: Generando chunks de texto...")
                progress_bar.progress(4/6)
                
                resultado_paso4 = pipeline.paso_4_generar_chunks()
                if not resultado_paso4:
                    raise Exception("Error en la generaci√≥n de chunks")
                
                log_area.text(f"‚úÖ Paso 4 completado: {pipeline.stats['chunks_generados']} chunks generados")
                
                # Paso 5: Generaci√≥n de embeddings
                status_text.text("Paso 5/6: Generando embeddings (puede tardar varios minutos)...")
                progress_bar.progress(5/6)
                
                resultado_paso5 = pipeline.paso_5_generar_embeddings_local()
                if not resultado_paso5:
                    raise Exception("Error en la generaci√≥n de embeddings")
                
                log_area.text(f"‚úÖ Paso 5 completado: {pipeline.stats['embeddings_creados']} embeddings generados")
                
                # Paso 6: Actualizaci√≥n de √≠ndice
                status_text.text("Paso 6/6: Actualizando √≠ndice FAISS...")
                progress_bar.progress(6/6)
                
                resultado_paso6 = pipeline.paso_6_actualizar_indice()
                if not resultado_paso6:
                    raise Exception("Error en la actualizaci√≥n del √≠ndice")
                
                log_area.text(f"‚úÖ Paso 6 completado: √çndice FAISS actualizado")
                
                # Completar progreso
                status_text.text("¬°Pipeline ETL completado exitosamente!")
                progress_bar.progress(1.0)
                
                # Estad√≠sticas finales
                stats = pipeline.stats
                
                st.success(f"""
                ‚úÖ **Pipeline ETL completado exitosamente**
                
                **Resumen del procesamiento:**
                - üìÖ Fecha procesada: {fecha}
                - ÔøΩ Directorio: {directorio_base}/{fecha_dir}/
                - ‚úÇÔ∏è Chunks generados: {stats.get('chunks_generados', 0):,}
                - üß† Embeddings creados: {stats.get('embeddings_creados', 0):,}
                - üìä Archivos indexados: {stats.get('indices_actualizados', 0)}
                - ‚è±Ô∏è Tiempo total: {stats.get('tiempo_total_segundos', 0):.1f} segundos
                
                **Archivos generados:**
                - `{directorio_base}/{fecha_dir}/json/` ‚Üí Sumario BOE
                - `{directorio_base}/{fecha_dir}/parquet/` ‚Üí Datos procesados
                - `{directorio_base}/{fecha_dir}/chunks/` ‚Üí Chunks de texto
                - `{directorio_base}/{fecha_dir}/embeddings/` ‚Üí Embeddings
                - `indices/` ‚Üí √çndice FAISS actualizado
                """)
                
                # Mostrar estad√≠sticas detalladas
                with st.expander("üìä Estad√≠sticas Detalladas", expanded=False):
                    st.json(stats)
                
                # Aviso de recarga autom√°tica
                st.info("""
                üîÑ **Recargando aplicaci√≥n para usar el nuevo √≠ndice...**
                
                La aplicaci√≥n se reiniciar√° autom√°ticamente para cargar el √≠ndice actualizado.
                """)
                
                # Esperar un momento y recargar
                import time
                time.sleep(3)
                
                # Limpiar cache y recargar aplicaci√≥n
                st.cache_resource.clear()
                st.rerun()
                
            except Exception as pipeline_error:
                st.error(f"‚ùå Error durante el pipeline: {str(pipeline_error)}")
                log_area.text(f"‚ùå Error detallado: {str(pipeline_error)}\n‚ùå Tipo: {type(pipeline_error).__name__}")
                
                # Mostrar informaci√≥n de debug
                with st.expander("üîç Informaci√≥n de Debug", expanded=False):
                    import traceback
                    st.code(traceback.format_exc())
                
                return
        
    except Exception as e:
        st.error(f"‚ùå Error general en el pipeline: {str(e)}")
        
        # √Årea de debugging
        with st.expander("üîç Informaci√≥n de Debug", expanded=False):
            st.code(str(e))

if __name__ == "__main__":
    main()
